{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7fb2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT_FILE: C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\online_retail_II.xlsx\n",
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
      "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
      "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
      "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
      "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
      "\n",
      "          InvoiceDate  Price  Customer ID         Country  \n",
      "0 2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
      "1 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "2 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "3 2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
      "4 2009-12-01 07:45:00   1.25      13085.0  United Kingdom  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 525461 entries, 0 to 525460\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Invoice      525461 non-null  object        \n",
      " 1   StockCode    525461 non-null  object        \n",
      " 2   Description  522533 non-null  object        \n",
      " 3   Quantity     525461 non-null  int64         \n",
      " 4   InvoiceDate  525461 non-null  datetime64[ns]\n",
      " 5   Price        525461 non-null  float64       \n",
      " 6   Customer ID  417534 non-null  float64       \n",
      " 7   Country      525461 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 32.1+ MB\n",
      "None\n",
      "\n",
      "Loaded dirty dataset sample:\n",
      "  InvoiceNo StockCode                      Description  Quantity         InvoiceDate  UnitPrice  CustomerID         Country\n",
      "0    526637     21901             KEY FOB , BACK DOOR         10 2010-10-12 13:16:00       0.65     14688.0  United Kingdom\n",
      "1    503062     84987  SET OF 36 TEATIME PAPER DOILIES         1 2010-03-29 16:48:00       1.45     14606.0  United Kingdom\n",
      "2    509202     22138    BAKING SET 9 PIECE RETROSPOT          3 2010-05-21 09:22:00       4.95     17738.0  United Kingdom\n",
      "3    514983     22223         CAKE PLATE LOVEBIRD PINK         3 2010-07-07 13:46:00       4.95     17129.0  United Kingdom\n",
      "4    524999    85099B          JUMBO BAG RED RETROSPOT         1 2010-10-01 17:34:00       4.21         NaN  United Kingdom\n",
      "\n",
      "Rows: 541225\n",
      "Missing CustomerID: 145462\n",
      "Missing InvoiceDate: 16296\n",
      "Negative Quantity: 38469\n",
      "Negative Price: 10635\n",
      "Duplicate rows: 19902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set correct INPUT_FILE and OUTPUT_FILE (discovered in workspace)\n",
    "INPUT_FILE = Path(r\"C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\online_retail_II.xlsx\")\n",
    "OUTPUT_FILE = Path(r\"C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail_dirty.csv\")\n",
    "OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the excel file (also keep df variable)\n",
    "df = pd.read_excel(INPUT_FILE, engine='openpyxl')\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"INPUT_FILE: {INPUT_FILE}\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# --- Quick sample from the dirty output (if it exists) ---\n",
    "try:\n",
    "    dirty_path = OUTPUT_FILE\n",
    "    if dirty_path.exists():\n",
    "        df_dirty = pd.read_csv(dirty_path, parse_dates=['InvoiceDate'], encoding='ISO-8859-1', low_memory=False)\n",
    "        print('\\nLoaded dirty dataset sample:')\n",
    "        print(df_dirty.head().to_string())\n",
    "\n",
    "        # summary counts for injected issues\n",
    "        cust_col = next((c for c in ['CustomerID', 'Customer ID'] if c in df_dirty.columns), None)\n",
    "        price_col = next((c for c in ['UnitPrice', 'Price'] if c in df_dirty.columns), None)\n",
    "        print(f\"\\nRows: {len(df_dirty)}\")\n",
    "        print('Missing CustomerID:', df_dirty[cust_col].isna().sum() if cust_col else 'N/A')\n",
    "        print('Missing InvoiceDate:', df_dirty['InvoiceDate'].isna().sum() if 'InvoiceDate' in df_dirty.columns else 'N/A')\n",
    "        print('Negative Quantity:', (df_dirty['Quantity'] < 0).sum() if 'Quantity' in df_dirty.columns else 'N/A')\n",
    "        print('Negative Price:', (df_dirty[price_col] < 0).sum() if price_col else 'N/A')\n",
    "        print('Duplicate rows:', df_dirty.duplicated().sum())\n",
    "    else:\n",
    "        print(f\"Dirty output not found at: {dirty_path}\")\n",
    "except Exception as e:\n",
    "    print('Error loading dirty sample:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ecd8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - INPUT_FILE in globals: True\n",
      "DEBUG - INPUT_FILE: C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail.csv\n",
      "DEBUG - exists: False\n",
      "DEBUG - suffix: .csv\n",
      "Dirty dataset successfully written to: C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail_dirty.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose:\n",
    "--------\n",
    "Introduce controlled, realistic noise into the UCI Online Retail dataset\n",
    "to simulate real-world data quality issues commonly found in e-commerce\n",
    "analytics pipelines.\n",
    "\n",
    "This intentionally dirty dataset will later be cleaned using SQL\n",
    "(PostgreSQL) and used for Marketing Mix Modeling (MMM).\n",
    "\n",
    "Author: Peace Odum\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration\n",
    "# -------------------------------\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Debug: show existing INPUT_FILE if present\n",
    "print(\"DEBUG - INPUT_FILE in globals:\", 'INPUT_FILE' in globals())\n",
    "if 'INPUT_FILE' in globals():\n",
    "    try:\n",
    "        print(\"DEBUG - INPUT_FILE:\", INPUT_FILE)\n",
    "        print(\"DEBUG - exists:\", INPUT_FILE.exists())\n",
    "        print(\"DEBUG - suffix:\", INPUT_FILE.suffix)\n",
    "    except Exception as e:\n",
    "        print(\"DEBUG - could not inspect INPUT_FILE:\", e)\n",
    "\n",
    "# Use existing INPUT_FILE if already set by the auto-detect cell; otherwise fall back\n",
    "if 'INPUT_FILE' not in globals():\n",
    "    try:\n",
    "        INPUT_FILE = PROJECT_ROOT / \"data\" / \"raw\" / \"online_retail.csv\"\n",
    "        OUTPUT_FILE = PROJECT_ROOT / \"data\" / \"raw\" / \"online_retail_dirty.csv\"\n",
    "    except NameError:\n",
    "        INPUT_FILE = Path(\"data/raw/online_retail.csv\")\n",
    "        OUTPUT_FILE = Path(\"data/raw/online_retail_dirty.csv\")\n",
    "\n",
    "GERMANY_ALIASES = [\"GER\", \"DE\", \"Deutschland\", \"Germany \"]\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Utility Functions\n",
    "# -------------------------------\n",
    "\n",
    "def set_random_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Ensure reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def load_data(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load raw online retail data.\"\"\"\n",
    "    # Auto-detect CSV vs Excel by suffix\n",
    "    path = Path(path)\n",
    "    if path.suffix.lower() in ['.xls', '.xlsx']:\n",
    "        df = pd.read_excel(path, engine='openpyxl')\n",
    "    else:\n",
    "        df = pd.read_csv(path, encoding='ISO-8859-1')\n",
    "    df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Noise Injection Functions\n",
    "# -------------------------------\n",
    "\n",
    "def introduce_missing_customer_ids(df: pd.DataFrame, pct: float = 0.08) -> None:\n",
    "    mask = np.random.rand(len(df)) < pct\n",
    "    if 'CustomerID' in df.columns:\n",
    "        df.loc[mask, \"CustomerID\"] = np.nan\n",
    "    elif 'Customer ID' in df.columns:\n",
    "        df.loc[mask, \"Customer ID\"] = np.nan\n",
    "\n",
    "\n",
    "def introduce_missing_invoice_dates(df: pd.DataFrame, pct: float = 0.03) -> None:\n",
    "    mask = np.random.rand(len(df)) < pct\n",
    "    if 'InvoiceDate' in df.columns:\n",
    "        df.loc[mask, \"InvoiceDate\"] = pd.NaT\n",
    "\n",
    "\n",
    "def introduce_returns(df: pd.DataFrame, pct: float = 0.05) -> None:\n",
    "    mask = np.random.rand(len(df)) < pct\n",
    "    if 'Quantity' in df.columns:\n",
    "        df.loc[mask, \"Quantity\"] = df.loc[mask, \"Quantity\"] * -1\n",
    "\n",
    "\n",
    "def introduce_price_errors(df: pd.DataFrame, neg_pct: float = 0.02, zero_pct: float = 0.02) -> None:\n",
    "    neg_mask = np.random.rand(len(df)) < neg_pct\n",
    "    zero_mask = np.random.rand(len(df)) < zero_pct\n",
    "\n",
    "    if 'UnitPrice' in df.columns:\n",
    "        df.loc[neg_mask, \"UnitPrice\"] = df.loc[neg_mask, \"UnitPrice\"] * -1\n",
    "        df.loc[zero_mask, \"UnitPrice\"] = 0\n",
    "    elif 'Price' in df.columns:\n",
    "        df.loc[neg_mask, \"Price\"] = df.loc[neg_mask, \"Price\"] * -1\n",
    "        df.loc[zero_mask, \"Price\"] = 0\n",
    "\n",
    "\n",
    "def corrupt_invoice_numbers(df: pd.DataFrame, pct: float = 0.02) -> None:\n",
    "    mask = np.random.rand(len(df)) < pct\n",
    "    suffixes = np.random.choice([\"X\", \"ERR\", \"?\"], size=mask.sum())\n",
    "    if 'InvoiceNo' in df.columns:\n",
    "        df.loc[mask, \"InvoiceNo\"] = (\n",
    "            df.loc[mask, \"InvoiceNo\"].astype(str) + suffixes\n",
    "        )\n",
    "    elif 'Invoice' in df.columns:\n",
    "        df.loc[mask, \"Invoice\"] = (\n",
    "            df.loc[mask, \"Invoice\"].astype(str) + suffixes\n",
    "        )\n",
    "\n",
    "\n",
    "def duplicate_rows(df: pd.DataFrame, pct: float = 0.03) -> pd.DataFrame:\n",
    "    dup_rows = df.sample(frac=pct, random_state=RANDOM_SEED)\n",
    "    return pd.concat([df, dup_rows], ignore_index=True)\n",
    "\n",
    "# Country inconsistencies are intentionally introduced ONLY for Germany,\n",
    "# as Germany is the target market for downstream MMM analysis.\n",
    "\n",
    "def introduce_country_inconsistencies(df: pd.DataFrame, pct: float = 0.10) -> None:\n",
    "    if 'Country' not in df.columns:\n",
    "        return\n",
    "    germany_mask = df[\"Country\"] == \"Germany\"\n",
    "    noise_mask = germany_mask & (np.random.rand(len(df)) < pct)\n",
    "\n",
    "    df.loc[noise_mask, \"Country\"] = np.random.choice(\n",
    "        GERMANY_ALIASES,\n",
    "        size=noise_mask.sum()\n",
    "    )\n",
    "\n",
    "\n",
    "def introduce_outliers(df: pd.DataFrame, pct: float = 0.01) -> None:\n",
    "    mask = np.random.rand(len(df)) < pct\n",
    "    if 'Quantity' in df.columns:\n",
    "        df.loc[mask, \"Quantity\"] = df.loc[mask, \"Quantity\"] * 20\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Main Pipeline\n",
    "# -------------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    global OUTPUT_FILE\n",
    "    set_random_seed(RANDOM_SEED)\n",
    "\n",
    "    # Use the discovered Excel file directly to avoid stray overrides\n",
    "    df = load_data(Path(r\"C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\online_retail_II.xlsx\"))\n",
    "\n",
    "    # Standardize column names used by noise functions\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    rename_map = {}\n",
    "    if 'Invoice' in df.columns:\n",
    "        rename_map['Invoice'] = 'InvoiceNo'\n",
    "    if 'Price' in df.columns:\n",
    "        rename_map['Price'] = 'UnitPrice'\n",
    "    if 'Customer ID' in df.columns:\n",
    "        rename_map['Customer ID'] = 'CustomerID'\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "\n",
    "    introduce_missing_customer_ids(df)\n",
    "    introduce_missing_invoice_dates(df)\n",
    "    introduce_returns(df)\n",
    "    introduce_price_errors(df)\n",
    "    corrupt_invoice_numbers(df)\n",
    "    introduce_country_inconsistencies(df)\n",
    "\n",
    "    df = duplicate_rows(df)\n",
    "    introduce_outliers(df)\n",
    "\n",
    "    # Shuffle rows to break natural ordering\n",
    "    df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    # Ensure OUTPUT_FILE is set to a sensible path\n",
    "    if 'OUTPUT_FILE' not in globals():\n",
    "        OUTPUT_FILE = Path(r\"C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail_dirty.csv\")\n",
    "\n",
    "    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "    print(f\"Dirty dataset successfully written to: {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f501ead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty path: C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail_dirty.csv\n",
      "\n",
      "Top country values:\n",
      "Country_clean\n",
      "United Kingdom          500407\n",
      "EIRE                      9960\n",
      "Germany                   7736\n",
      "France                    5941\n",
      "Netherlands               2862\n",
      "Spain                     1311\n",
      "Switzerland               1223\n",
      "Portugal                  1140\n",
      "Belgium                   1082\n",
      "Channel Islands            936\n",
      "Sweden                     929\n",
      "Italy                      754\n",
      "Australia                  678\n",
      "Cyprus                     569\n",
      "Austria                    558\n",
      "Greece                     535\n",
      "Denmark                    446\n",
      "United Arab Emirates       438\n",
      "Norway                     375\n",
      "Finland                    367\n",
      "Unspecified                317\n",
      "USA                        253\n",
      "Deutschland                232\n",
      "Japan                      230\n",
      "GER                        221\n",
      "Poland                     203\n",
      "DE                         192\n",
      "Malta                      175\n",
      "Lithuania                  158\n",
      "Singapore                  125\n",
      "RSA                        115\n",
      "Bahrain                    110\n",
      "Hong Kong                   79\n",
      "Thailand                    78\n",
      "Canada                      78\n",
      "Israel                      76\n",
      "Iceland                     73\n",
      "Korea                       65\n",
      "Brazil                      63\n",
      "West Indies                 55\n",
      "\n",
      "Rows matching Germany aliases (case-insensitive): 8381\n",
      "Unique matched values: ['DE', 'Deutschland', 'GER', 'Germany']\n",
      "\n",
      "Sample rows with Germany variants:\n",
      "    InvoiceNo Country_clean\n",
      "91     527496       Germany\n",
      "134    501545       Germany\n",
      "160    500376       Germany\n",
      "180    509210   Deutschland\n",
      "202    513876       Germany\n",
      "237    530970       Germany\n",
      "314    531190       Germany\n",
      "354    528957   Deutschland\n",
      "388   C522713       Germany\n",
      "407    522339       Germany\n",
      "425    532961       Germany\n",
      "508    491805            DE\n",
      "561    519501       Germany\n",
      "565    492950           GER\n",
      "568    513876       Germany\n",
      "602    491709       Germany\n",
      "685    491738       Germany\n",
      "693    514226       Germany\n",
      "724    535419       Germany\n",
      "771    505335       Germany\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load dirty dataset\n",
    "dirty_path = OUTPUT_FILE if 'OUTPUT_FILE' in globals() else Path(r\"C:\\Users\\peace\\Downloads\\Datasets\\Retail dataset\\data\\raw\\online_retail_dirty.csv\")\n",
    "print('Dirty path:', dirty_path)\n",
    "df_dirty = pd.read_csv(dirty_path, parse_dates=['InvoiceDate'], encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "df_dirty['Country_clean'] = df_dirty['Country'].astype(str).str.strip()\n",
    "\n",
    "print('\\nTop country values:')\n",
    "print(df_dirty['Country_clean'].value_counts().head(40).to_string())\n",
    "\n",
    "aliases = ['ger', 'de', 'deutschland', 'germany']\n",
    "mask = df_dirty['Country_clean'].str.lower().isin(aliases)\n",
    "\n",
    "print(f\"\\nRows matching Germany aliases (case-insensitive): {mask.sum()}\")\n",
    "print('Unique matched values:', sorted(df_dirty.loc[mask, 'Country_clean'].unique().tolist()))\n",
    "\n",
    "print('\\nSample rows with Germany variants:')\n",
    "key_invoice = 'InvoiceNo' if 'InvoiceNo' in df_dirty.columns else ('Invoice' if 'Invoice' in df_dirty.columns else None)\n",
    "cols = [c for c in [key_invoice, 'Country_clean'] if c]\n",
    "print(df_dirty.loc[mask, cols].head(20).to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
